{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP4Cy7oVkfU4F8zdyRYiFvt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahul-727/SPR-/blob/main/2348544_Lab8_SPR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NqykFcbThtxq"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Viterbi Algorithm ensures the speech recognition system correctly maps acoustic feature vectors (observations) to the phoneme sequence \"hello,\" determining the most likely interpretation of the audio input."
      ],
      "metadata": {
        "id": "6mmX3_5Gi1Re"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* designed to help a computer recognize the word \"hello\" from a sequence of sounds or acoustic signals.\n",
        "* Breaking Down the Word:\n",
        "The word \"hello\" is split into smaller sound units called phonemes: /h/, /e/, /l/, /o/.\n",
        "* Understanding the Sounds:\n",
        "Each phoneme produces certain sound patterns, which the program identifies as observations (O1, O2, O3, O4).\n",
        "* How Sounds are Linked:\n",
        "The program uses rules (probabilities) to understand:How likely it is to move from one sound to the next (e.g., from /h/ to /e/), and\n",
        "How likely a sound matches the observed signal (e.g., /h/ produces O1).\n",
        "* When the program hears a sequence of sounds, it tries to figure out which sequence of phonemes (hidden states) is most likely responsible for those sounds. It calculates this using the Viterbi Algorithm, which finds the best path through a series of possible states."
      ],
      "metadata": {
        "id": "TlZcbazej3x-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transition Probability Matrix (A)\n",
        "\n",
        "* This defines the probability of transitioning from one hidden state (phoneme) to another.\n",
        "Example: The probability of moving from /h/ to /e/ is 0.7.\n",
        "\n",
        "Emission Probability Matrix (B)\n",
        "* This defines the probability of emitting an observation (acoustic feature) given a specific hidden state.\n",
        "Example: The probability of observing feature vector O1 from state /h/ is 0.6.\n",
        "\n",
        "Initial Probabilities (Ï€)\n",
        "\n",
        "* This specifies the probability of starting in a particular hidden state.\n",
        "Example: The probability of starting in state /h/ is 1.0.\n",
        "\n",
        "Observation Sequence (O)\n",
        "* This is the sequence of observed feature vectors [O1, O2, O3, O4], represented as indices [0, 1, 2, 3]."
      ],
      "metadata": {
        "id": "lxp8EXAiigLR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def viterbi_algorithm(A, B, pi, O):\n",
        "    n_states = A.shape[0]\n",
        "    n_observations = len(O)\n",
        "\n",
        "    # Initialize the Viterbi table and backpointer table\n",
        "    viterbi = np.zeros((n_states, n_observations))\n",
        "    backpointer = np.zeros((n_states, n_observations), dtype=int)\n",
        "\n",
        "    # Initialization step\n",
        "    viterbi[:, 0] = pi * B[:, O[0]]\n",
        "\n",
        "    # Recursion step\n",
        "    for t in range(1, n_observations):\n",
        "        for s in range(n_states):\n",
        "            prob = viterbi[:, t-1] * A[:, s] * B[s, O[t]]\n",
        "            viterbi[s, t] = np.max(prob)\n",
        "            backpointer[s, t] = np.argmax(prob)\n",
        "\n",
        "    # Termination step\n",
        "    best_path_prob = np.max(viterbi[:, -1])\n",
        "    best_last_state = np.argmax(viterbi[:, -1])\n",
        "\n",
        "    # Backtrace to find the best path\n",
        "    best_path = [best_last_state]\n",
        "    for t in range(n_observations - 1, 0, -1):\n",
        "        best_last_state = backpointer[best_last_state, t]\n",
        "        best_path.insert(0, best_last_state)\n",
        "\n",
        "    return best_path, best_path_prob"
      ],
      "metadata": {
        "id": "VkdZY_vDhvAn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "states = [\"/h/\", \"/e/\", \"/l/\", \"/o/\"]\n",
        "observations = [\"O1\", \"O2\", \"O3\", \"O4\"]\n",
        "\n",
        "A = np.array([\n",
        "    [0.0, 0.7, 0.3, 0.0],\n",
        "    [0.0, 0.2, 0.6, 0.2],\n",
        "    [0.0, 0.0, 0.3, 0.7],\n",
        "    [0.0, 0.0, 0.1, 0.9]\n",
        "])\n",
        "\n",
        "B = np.array([\n",
        "    [0.6, 0.2, 0.1, 0.1],\n",
        "    [0.1, 0.7, 0.1, 0.1],\n",
        "    [0.1, 0.1, 0.6, 0.2],\n",
        "    [0.2, 0.1, 0.2, 0.5]\n",
        "])\n",
        "\n",
        "pi = np.array([1.0, 0.0, 0.0, 0.0])\n",
        "\n",
        "O = [0, 1, 2, 3]"
      ],
      "metadata": {
        "id": "rYiXAAfxiAWi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_path, best_path_prob = viterbi_algorithm(A, B, pi, O)\n",
        "best_path_states = [states[state] for state in best_path]\n",
        "\n",
        "print(\"Most likely sequence of phoneme states:\", best_path_states)\n",
        "print(\"Probability of the most likely sequence:\", best_path_prob)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kX5oreDjiEwy",
        "outputId": "a3276d3f-0019-4495-ed49-4fee20033859"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most likely sequence of phoneme states: ['/h/', '/e/', '/l/', '/o/']\n",
            "Probability of the most likely sequence: 0.03704399999999999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The sequence of states ['/h/', '/e/', '/l/', '/o/'] represents the phonemes of the word \"hello.\" This indicates that the observation sequence [O1, O2, O3, O4] corresponds to the acoustic features of these phonemes in the given order. Thus, the Viterbi Algorithm successfully maps the observations to the word \"hello.\"\n",
        "\n",
        "Probability of the Most Likely Sequence:\n",
        "The computed probability of 0.03704 represents the likelihood of observing the given sequence of acoustic features [O1, O2, O3, O4] under the Hidden Markov Model (HMM) parameters (transition probabilities, emission probabilities, and initial probabilities).\n",
        "\n",
        "* Although the probability is relatively small, this is expected in HMMs due to the multiplicative nature of probabilities, especially over multiple time steps.\n",
        "This is the most likely path compared to all other possible paths through the HMM, meaning it is the best explanation for the observations."
      ],
      "metadata": {
        "id": "NBWKVCuIjm9i"
      }
    }
  ]
}